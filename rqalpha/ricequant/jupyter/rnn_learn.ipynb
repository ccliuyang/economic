{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import reduce  \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class test_1(object):\n",
    "    def __init__(self,\n",
    "                batch_size = 128,\n",
    "                learning_rate = 0.001,\n",
    "                training_epoch = 10,\n",
    "                display_step = 5,\n",
    "                layer_units_num = 100):\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_epoch = training_epoch\n",
    "        self.display_step = display_step\n",
    "        self.layer_units_num = layer_units_num\n",
    "        \n",
    "    def dense_to_one_hot(self,labels_dense):\n",
    "        \"\"\"标签 转换one hot 编码\n",
    "        输入labels_dense 必须为非负数\n",
    "        2016-11-21\n",
    "        \"\"\"\n",
    "        num_classes = len(np.unique(labels_dense)) # np.unique 去掉重复函数\n",
    "        raws_labels = labels_dense.shape[0]\n",
    "        index_offset = np.arange(raws_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((raws_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "        return labels_one_hot  \n",
    "        \n",
    "    def Preprocessing(self, trainX, trainY, seed=False):\n",
    "        trainY = self.dense_to_one_hot(trainY)\n",
    "        self.in_length= in_length= trainX.shape[1]\n",
    "        self.in_width= in_width= trainX.shape[2]\n",
    "        self.out_classes= out_classes= trainY.shape[1]\n",
    "        \n",
    "        if seed:\n",
    "            tf.set_random_seed(20170204)\n",
    "        weights = {\n",
    "            'out': tf.Variable(tf.truncated_normal(shape=[self.layer_units_num, out_classes], \n",
    "                                                mean=0., stddev=1., seed=None, dtype=tf.float32),\n",
    "                               trainable=True, name='Weight_full_out')\n",
    "        }\n",
    "        \n",
    "        biases = {\n",
    "            'out': tf.Variable(tf.truncated_normal([out_classes]), trainable=True, name= 'Biases_full_out')\n",
    "        }    \n",
    "        \n",
    "        self.weights = weights\n",
    "        self.biases = biases        \n",
    "        \n",
    "        X = tf.placeholder(dtype=tf.float32, shape=[None, in_length, in_width], name='trainX') # 批次，时间序列，多因子\n",
    "        Y = tf.placeholder(dtype= tf.float32, shape=[None, out_classes], name='trainY') \n",
    "        keep_prob = tf.placeholder(dtype= tf.float32)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.keep_prob = keep_prob  \n",
    "        \n",
    "    def Network(self):\n",
    "        \n",
    "        with tf.name_scope('layer_1'):            \n",
    "            monolayer_1 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num, \n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)            \n",
    "            monolayer_1 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_1, output_keep_prob= keep_prob)\n",
    "\n",
    "        \n",
    "        with tf.name_scope('layer_2'):        \n",
    "            monolayer_2 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num,\n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "            monolayer_2 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_2, output_keep_prob= keep_prob)\n",
    "        \n",
    "        with tf.name_scope('layer_3'):                  \n",
    "            monolayer_3 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num,\n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "            monolayer_3 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_3, output_keep_prob= keep_prob)\n",
    "        \n",
    "        with tf.name_scope('layer_Final'):\n",
    "            monolayer_final = tf.nn.rnn_cell.BasicLSTMCell(num_units=self.layer_units_num, \n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "        \n",
    "        with tf.name_scope('Layer_Structure_Combination'):\n",
    "            layer_units_num = self.layer_units_num\n",
    "            Layers = tf.nn.rnn_cell.MultiRNNCell(cells=[monolayer_1,monolayer_2,monolayer_3,monolayer_final],\n",
    "                                                state_is_tuple = True)    \n",
    "        self.Layers = Layers\n",
    "        return Layers\n",
    "        \n",
    "    def Model(self):\n",
    "        X = self.X\n",
    "        keep_prob = self.keep_prob\n",
    "        \n",
    "        X = tf.transpose(X, [1, 0, 2])\n",
    "        X = tf.reshape(X, [-1,self.in_width])\n",
    "        X = tf.split(split_dim=0, num_split=self.in_length, value=X)\n",
    "        \n",
    "        with tf.name_scope('layer_1'):            \n",
    "            monolayer_1 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num, \n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)            \n",
    "            monolayer_1 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_1, output_keep_prob= keep_prob)\n",
    "\n",
    "        \n",
    "        with tf.name_scope('layer_2'):        \n",
    "            monolayer_2 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num,\n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "            monolayer_2 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_2, output_keep_prob= keep_prob)\n",
    "        \n",
    "        with tf.name_scope('layer_3'):                  \n",
    "            monolayer_3 = tf.nn.rnn_cell.BasicLSTMCell(num_units= self.layer_units_num,\n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "            monolayer_3 = tf.nn.rnn_cell.DropoutWrapper(cell=monolayer_3, output_keep_prob= keep_prob)\n",
    "        \n",
    "        with tf.name_scope('layer_Final'):\n",
    "            monolayer_final = tf.nn.rnn_cell.BasicLSTMCell(num_units=self.layer_units_num, \n",
    "                                                       forget_bias=1., state_is_tuple=True, activation=tf.tanh)\n",
    "        \n",
    "        with tf.name_scope('Layer_Structure_Combination'):\n",
    "            layer_units_num = self.layer_units_num\n",
    "            Layers = tf.nn.rnn_cell.MultiRNNCell(cells=[monolayer_1,monolayer_2,monolayer_3,monolayer_final],\n",
    "                                                state_is_tuple = True)    \n",
    "        \n",
    "        outputs,_ = tf.nn.rnn(cell=monolayer_final, inputs=X, dtype=tf.float32)\n",
    "        output = outputs[-1]\n",
    "\n",
    "        return tf.nn.bias_add(value= tf.matmul(output, self.weights['out']), bias= self.biases['out'])  \n",
    "        \n",
    "    def train(self, trainX, trainY, seed=False):\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        \n",
    "        self.Preprocessing(trainX, trainY, seed)\n",
    "        \n",
    "        tmp = self.Model()\n",
    "        \n",
    "        self.predict = tf.nn.softmax(tmp)\n",
    "        \n",
    "        self.cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(tmp, self.Y))\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate= self.learning_rate) # 0 设置训练器\n",
    "        grads_and_vars = optimizer.compute_gradients(self.cost)\n",
    "        for i, (grid, var) in enumerate(grads_and_vars):\n",
    "            if grid != None:\n",
    "                grid = tf.clip_by_value(grid, -1., 1.)\n",
    "                grads_and_vars[i] = (grid, var)\n",
    "        optimizer = optimizer.apply_gradients(grads_and_vars)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.correct_pred = tf.equal(tf.argmax(tmp,1), tf.argmax(self.Y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "        self.accuracy = accuracy\n",
    "        \n",
    "        #self.init = tf.global_variables_initializer()   \n",
    "        self.init = tf.initialize_all_variables()\n",
    "    def fit(self,trainX, trainY, dropout = 0.3, seed=True):\n",
    "        self.train(trainX, trainY, seed=True)\n",
    "        sess = self.sess\n",
    "        sess.run(self.init)\n",
    "        batch_size = self.batch_size\n",
    "        trainY = self.dense_to_one_hot(trainY)\n",
    "        for ep in range(self.training_epoch):\n",
    "            for i in range(int(len(trainX)/batch_size)+1):\n",
    "                if i < int(len(trainX)/batch_size)+1:\n",
    "                    batch_x = trainX[i*batch_size : (i+1)*batch_size]\n",
    "                    batch_y = trainY[i*batch_size : (i+1)*batch_size]\n",
    "                elif i== int(len(trainX)/batch_size)+1:\n",
    "                    batch_x = trainX[-batch_size:]\n",
    "                    batch_y = trainY[-batch_size:]\n",
    "                sess.run(self.optimizer, feed_dict={self.X:batch_x, self.Y:batch_y, self.keep_prob:(1.-dropout)})\n",
    "            if ep%self.display_step==0:                \n",
    "                loss, acc = sess.run([self.cost,self.accuracy], feed_dict={self.X:trainX, self.Y:trainY, self.keep_prob:1.})\n",
    "                print (str(ep)+\"th \"+'Epoch Loss = {:.5f}'.format(loss)+\" Training Accuracy={:.5f}\".format(acc))\n",
    "        self.sess= sess\n",
    "        print(\"Optimization Finished!\") \n",
    "    \n",
    "    def pred_prob(self, testX):\n",
    "        sess = self.sess\n",
    "        batch_size = self.batch_size\n",
    "        trainX = testX\n",
    "        predict_output = np.zeros([1,self.out_classes])\n",
    "        for i in range(int(len(trainX)/batch_size)+1):\n",
    "            if i < int(len(trainX)/batch_size)+1:\n",
    "                batch_x = trainX[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = trainY[i*batch_size : (i+1)*batch_size]\n",
    "            elif i== int(len(trainX)/batch_size)+1:\n",
    "                batch_x = trainX[-batch_size:]\n",
    "                batch_y = trainY[-batch_size:]\n",
    "            tp = sess.run(self.predict,feed_dict={self.X:batch_x, self.keep_prob:1.})\n",
    "            predict_output = np.row_stack([predict_output, tp])\n",
    "        predict_output = np.delete(predict_output, obj=0, axis=0)\n",
    "        return predict_output\n",
    "    \n",
    "    def pred(self, testX):\n",
    "        pred_prob = self.pred_prob(testX)\n",
    "        return np.argmax(pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=test_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8a6664a744a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_to_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-80eeb94ef4f6>\u001b[0m in \u001b[0;36mdense_to_one_hot\u001b[1;34m(self, labels_dense)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mindex_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraws_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraws_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mlabels_one_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_offset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabels_dense\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlabels_one_hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 18 is out of bounds for size 18"
     ]
    }
   ],
   "source": [
    "test.dense_to_one_hot(np.array([1,1,2,2,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_dense=np.array([1,1,2,2,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(labels_dense))\n",
    "raws_labels = labels_dense.shape[0]#多少列数据\n",
    "index_offset = np.arange(raws_labels) * num_classes\n",
    "labels_one_hot = np.zeros((raws_labels, num_classes))\n",
    "labels_one_hot.flat[index_offset + labels_dense.ravel()-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-bd001a70d401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels_one_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "labels_one_hot.transpose([1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
